<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Workshop 2021</title><link rel="preload" href="/_next/static/css/2786522978a02f025205.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2786522978a02f025205.css" data-n-g=""/><link rel="preload" href="/_next/static/css/f2fce7b83fe6ca04479b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f2fce7b83fe6ca04479b.css" data-n-p=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-03338d1f0abd6c64b75e.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.4df82c4704a0136f6a4b.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.c6a8bf6988d7f4eaa7c5.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-5b2207eda8db40c16cba.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.a574dc0b5846fc81ad3b.js" as="script"/><link rel="preload" href="/_next/static/chunks/1558ef9ce728a667623917e07efc98a0687ed212.cdf705ea9d3ade502405.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/workshop-edef57020c68610304bb.js" as="script"/></head><body><div id="__next"><div class="layout_background__1AVEa undefined"><header class="layout_header__2rhWq"><div class="navbar_navwrapper__15zia"><div class="navbar_gradbar__1Xi5u"></div><nav class="navbar_navbar__3gnco"><span class="utils_headingLg__de7p0 navbar_navbarlogo__PLEwr"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__358pJ" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar__QVPSR" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__3ICSG navbar_pushright__3G2DM"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/get_started">How To</a></li><li class="navbar_navitem__3ICSG"><a href="/results">Results</a></li><li class="navbar_navitem__3ICSG"><a href="https://arxiv.org/abs/2102.01672" target="_blank">Paper</a></li><li class="navbar_navitem__3ICSG"><a href="/team">Team</a></li><li class="navbar_navitem__3ICSG"><a href="/nl_augmenter">NL-Augmenter</a></li><li class="navbar_navitem__3ICSG"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__2t4v2"><main><article><span class="utils_headingXl__1XecN">GEM Workshop at ACL 2021</span><span class="utils_smallSpace__375iy"></span><div><p>The workshop will be held as part of <a href="https://2021.aclweb.org/">ACL-IJCNLP 2021</a>, August 1-6, 2021. It will take place on August 6. It is endorsed by the ACL Special Interest Group on Natural Language Generation (<a href="https://aclweb.org/aclwiki/SIGGEN">SIGGEN</a>).</p>
<p><strong>Note: Our system output submission form is perpetually open, please continue participating in our benchmark.</strong></p>
<h2 id="workshop-overview">Workshop Overview</h2>
<p>Natural language generation is one of the most active research fields in NLP, with generation, summarization, and dialog among the <a href="https://acl2020.org/blog/general-conference-statistics/">most submitted-to tracks</a>. As such, the number of available datasets, metrics, models, and evaluation strategies are increasing rapidly. This is leading to the situation where new models are often evaluated on different anglo-centric tasks with incompatible evaluation setups. With GEM, we are aiming to solve this problem by standardizing and improving the corpora on which to evaluate NLG models, and by supporting the development of better evaluation approaches. Submitted papers analyze the state of NLG evaluation and propose better alternatives. Moreover, we are organizing the living GEM benchmark which incorporates new advances in data and human and automatic evaluation to make it easier to evaluate models on challenging tasks with the correct tools. In our shared task, models were applied to up to 11 tasks in 18 languages, 80 challenge sets, and their outputs characterized using a combination of human evaluation and over 50 automatic metrics.
Through the presented papers and the shared task, we aim to uncover shortcomings and opportunities for progress.</p>
<h2 id="schedule">Schedule</h2>
<p>All times in UTC, please use a converter like <a href="https://www.timeanddate.com/worldclock/converter.html?iso=20210713T140000&#x26;p1=1440">this one</a> to convert to your local time.</p>
<p>We do not distinguish between workshop papers and Findings of the ACL papers that are being presented - they are all great! Links to all papers are coming soon!</p>
<table>
<thead>
<tr>
<th>Time (UTC)</th>
<th>Session</th>
</tr>
</thead>
<tbody>
<tr>
<td>11:30 - 12:00</td>
<td><strong>Welcome and Explanation of Logistics</strong></td>
</tr>
<tr>
<td>12:00 - 13:00</td>
<td><strong>Poster Session</strong></td>
</tr>
<tr>
<td></td>
<td>Evaluating the Efficacy of Summarization Evaluation across Languages  <br /> <em>Fajri Koto, Jey Han Lau, and Timothy Baldwin</em></td>
</tr>
<tr>
<td></td>
<td>Automatic Text Simplification for Social Good: Progress and Challenges   <br />  <em>Sanja Stajner</em></td>
</tr>
<tr>
<td></td>
<td>Flesch-Kincaid is Not a Text Simplification Evaluation Metric <br />  <em>Teerapaun Tanprasert and David Kauchak</em></td>
</tr>
<tr>
<td></td>
<td>Human Perception in Natural Language Generation <br />       <em>Lorenzo De Mattei, Huiyuan Lai, Felice Dell'Orletta, and Malvina Nissim</em></td>
</tr>
<tr>
<td></td>
<td>Semantic Similarity Based Evaluation for Abstractive News Summarization <br /> <em>Figen Beken Fikri, Kemal Oflazer, and Berrin Yanikoglu</em></td>
</tr>
<tr>
<td></td>
<td>Shades of BLEU, Flavours of Success: The Case of MultiWOZ <br /> <em>Tomáš Nekvinda and Ondřej Dušek</em></td>
</tr>
<tr>
<td>13:00 - 13:45</td>
<td><strong>Panel Discussion with Hady Elsahar, Seraphina Goldfarb-Tarrant, He He, and Ehud Reiter</strong></td>
</tr>
<tr>
<td>13:45 - 14:00</td>
<td><em>Break</em></td>
</tr>
<tr>
<td>14:00 - 15:00</td>
<td><strong>Talk Session</strong></td>
</tr>
<tr>
<td></td>
<td>Personalized Response Generation with Tensor Factorization   <br />  <em>Zhenghui Wang, Lingxiao Luo, and Diyi Yang</em></td>
</tr>
<tr>
<td></td>
<td>A Review of Human Evaluation for Style Transfer   <br />  <em>Eleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, and Marine Carpuat</em></td>
</tr>
<tr>
<td></td>
<td>GOT: Testing for Originality in Natural Language Generation   <br />  <em>Jennifer Brooks and Abdou Youssef</em></td>
</tr>
<tr>
<td></td>
<td>Evaluating Text Generation from Discourse Representation Structures   <br />  <em>Chunliu Wang, Rik van Noord, Arianna Bisazza, and Johan Bos</em></td>
</tr>
<tr>
<td>15:00 - 16:00</td>
<td><strong>Poster Session</strong></td>
</tr>
<tr>
<td></td>
<td>Detecting Hallucinated Content in Conditional Neural Sequence Generation   <br />  <em>Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Paco Guzman, Luke Zettlemoyer, and Marjan Ghazvininejad</em></td>
</tr>
<tr>
<td></td>
<td>Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation   <br />  <em>Prakhar Gupta, Yulia Tsvetkov, and Jeffrey Bigham</em></td>
</tr>
<tr>
<td></td>
<td>Perceptual Models of Machine-Edited Text   <br />  <em>Elizabeth Merkhofer, Monica-Ann Mendoza, Rebecca Marvin, and John Henderson</em></td>
</tr>
<tr>
<td></td>
<td>Improving Automated Evaluation of Open Domain Dialog via Diverse Reference Augmentation   <br />  <em>Varun Gangal, Harsh Jhamtani, Eduard Hovy, and Taylor Berg-Kirkpatrick</em></td>
</tr>
<tr>
<td></td>
<td>XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages   <br />  <em>Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang, M. Sohel Rahman, and Rifat Shahriyar</em></td>
</tr>
<tr>
<td></td>
<td>Human Evaluation of Creative NLG Systems: An Interdisciplinary Survey on Recent Papers   <br />  <em>Mika Hämäläinen and Khalid Alnajjar</em></td>
</tr>
<tr>
<td>16:00 - 17:00</td>
<td><strong>Keynote by Asli Celikyilmaz</strong></td>
</tr>
<tr>
<td>17:00 - 17:45</td>
<td><strong>Panel Discussion with Anya Belz, Asli Celikyilmaz, Mike Lewis, Lisa Li, and Wang Lu</strong></td>
</tr>
<tr>
<td>17:45 - 18:00</td>
<td><em>Break</em></td>
</tr>
<tr>
<td>18:00 - 19:00</td>
<td><strong>GEM Overview Session</strong></td>
</tr>
<tr>
<td></td>
<td>The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics   <br />  <em>Everyone listed on the <a href="/team">GEM team page</a></em></td>
</tr>
<tr>
<td></td>
<td>Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards   <br />  <em>Angelina McMillan-Major, Salomey Osei, Juan Diego Rodriguez, Pawan Sasanka Ammanamanchi, Sebastian Gehrmann, and Yacine Jernite</em></td>
</tr>
<tr>
<td></td>
<td>Preliminary Results of the GEM Thared Task   <br />  <em>GEM Organizers</em></td>
</tr>
<tr>
<td></td>
<td>NL-Augmenter: A Collaborative Effort to Transform and Filter Text Datasets   <br />  <em>Kaustubh Dhole, Sebastian Gehrmann, Jascha Sohl-Dickstein, Varun Prashant Gangal, Tongshuang Wu, Simon Mille, Zhenhao Li, Aadesh Gupta, Samson Tan, Saad Mahmood, Ashish Shrivastava, Ondrej Dusek, and Jinho D. Choi</em></td>
</tr>
<tr>
<td>19:00 - 20:00</td>
<td><strong>GEM System Session</strong></td>
</tr>
<tr>
<td></td>
<td>Structure-to-Text Generation with Self-Training, Acceptability Classifiers and Context-Conditioning for the GEM Shared Task   <br />  <em>Shreyan Bakshi, Soumya Batra, Peyman Heidari, Ankit Arun, Shashank Jain, and Michael White</em></td>
</tr>
<tr>
<td></td>
<td>NUIG-DSI’s submission to The GEM Benchmark 2021   <br />  <em>Nivranshu Pasricha, Mihael Arcan, and Paul Buitelaar</em></td>
</tr>
<tr>
<td></td>
<td>System Description for the CommonGen task with the POINTER model   <br />  <em>Anna Shvets</em></td>
</tr>
<tr>
<td></td>
<td>SimpleNER Sentence Simplification System for GEM 2021   <br />  <em>K V Aditya Srivatsa, Monil Gokani, and Manish Shrivastava</em></td>
</tr>
<tr>
<td>20:00 - 21:00</td>
<td><strong>Poster Session</strong></td>
</tr>
<tr>
<td></td>
<td>GO FIGURE: A Meta Evaluation of Factuality in Summarization   <br />  <em>Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, and Jianfeng Gao</em></td>
</tr>
<tr>
<td></td>
<td>TellMeWhy: A Dataset for Answering Why-Questions in Narratives   <br />  <em>Yash Kumar Lal, Nathanael Chambers, Raymond Mooney and Niranjan Balasubramanian</em></td>
</tr>
<tr>
<td></td>
<td>Is Human Scoring the Best Criteria for Summary Evaluation?   <br />  <em>Oleg Vasilyev and John Bohannon</em></td>
</tr>
<tr>
<td></td>
<td>Are Larger Pretrained Language Models Uniformly Better? Comparing Performance at the Instance Level   <br />  <em>Ruiqi Zhong, Dhruba Ghosh, Dan Klein, and Jacob Steinhardt</em></td>
</tr>
<tr>
<td></td>
<td>Elaborative Simplification: Content Addition and Explanation Generation in Text Simplification   <br />  <em>Neha Srikanth and Junyi Jessy Li</em></td>
</tr>
<tr>
<td></td>
<td>Decoding Methods for Neural Narrative Generation   <br />  <em>Alexandra DeLucia, Aaron Mueller, Xiang Lisa Li, and João Sedoc</em></td>
</tr>
</tbody>
</table>
<h2 id="important-dates">Important Dates</h2>
<h3 id="workshop">Workshop</h3>
<p><code>February 2</code> First Call for Shared Task Submissions and Papers, Release of the Training Data</p>
<p><code>May 3</code> Workshop Paper Due Date (excl. shared tasks) <strong>UPDATED</strong></p>
<p><code>May 28</code>  Notification of Acceptance (excl. shared tasks)</p>
<p><code>June 7</code>  Camera-ready papers due (excl. shared tasks)</p>
<h3 id="shared-task-dates">Shared Task Dates</h3>
<p><strong>Modeling</strong></p>
<p><code>February 2</code> Release of the training Data</p>
<p><code>March 29</code> Release of the test sets</p>
<p><code>May 14</code> Modeling submissions due</p>
<p><code>June 11</code> System Descriptions and Analyses due</p>
<p><code>June 25</code> Notification of Acceptance (shared task)</p>
<p><code>July 9</code> Camera-ready papers and task descriptions due</p>
<p><code>August 5-6</code> Workshop Dates</p>
<h2 id="organization">Organization</h2>
<p>The workshop is organized by</p>
<ul>
<li><a href="https://atcbosselut.github.io/">Antoine Bosselut</a> (Stanford University)</li>
<li><a href="http://www.cs.cornell.edu/~esindurmus/">Esin Durmus</a> (Cornell University)</li>
<li><a href="https://vgtomahawk.github.io/">Varun Prashant Gangal</a> (Carnegie Mellon University)</li>
<li><a href="https://sebastiangehrmann.com">Sebastian Gehrmann</a> (Google Research)</li>
<li><a href="https://yjernite.github.io/">Yacine Jernite</a> (Hugging Face)</li>
<li><a href="http://homepages.inf.ed.ac.uk/lperez/">Laura Perez-Beltrachini</a> (University of Edinburgh)</li>
<li><a href="https://webpages.uncc.edu/sshaikh2/">Samira Shaikh</a> (UNC Charlotte)</li>
<li><a href="https://cocoxu.github.io/">Wei Xu</a> (Georgia Tech)</li>
</ul>
<p>The shared task and the GEM environment is organized by a larger team which is listed on <a href="/team">this page</a>.</p>
</div></article></main><div class="layout_push__1J9g0"></div></div><footer class="layout_footer__127N0 utils_eggshell__Njxsh"><span class="layout_backToHome__1vZsp"><a href="/">← Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__k083p">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"workshopData":{"contentHtml":"\u003cp\u003eThe workshop will be held as part of \u003ca href=\"https://2021.aclweb.org/\"\u003eACL-IJCNLP 2021\u003c/a\u003e, August 1-6, 2021. It will take place on August 6. It is endorsed by the ACL Special Interest Group on Natural Language Generation (\u003ca href=\"https://aclweb.org/aclwiki/SIGGEN\"\u003eSIGGEN\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote: Our system output submission form is perpetually open, please continue participating in our benchmark.\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"workshop-overview\"\u003eWorkshop Overview\u003c/h2\u003e\n\u003cp\u003eNatural language generation is one of the most active research fields in NLP, with generation, summarization, and dialog among the \u003ca href=\"https://acl2020.org/blog/general-conference-statistics/\"\u003emost submitted-to tracks\u003c/a\u003e. As such, the number of available datasets, metrics, models, and evaluation strategies are increasing rapidly. This is leading to the situation where new models are often evaluated on different anglo-centric tasks with incompatible evaluation setups. With GEM, we are aiming to solve this problem by standardizing and improving the corpora on which to evaluate NLG models, and by supporting the development of better evaluation approaches. Submitted papers analyze the state of NLG evaluation and propose better alternatives. Moreover, we are organizing the living GEM benchmark which incorporates new advances in data and human and automatic evaluation to make it easier to evaluate models on challenging tasks with the correct tools. In our shared task, models were applied to up to 11 tasks in 18 languages, 80 challenge sets, and their outputs characterized using a combination of human evaluation and over 50 automatic metrics.\nThrough the presented papers and the shared task, we aim to uncover shortcomings and opportunities for progress.\u003c/p\u003e\n\u003ch2 id=\"schedule\"\u003eSchedule\u003c/h2\u003e\n\u003cp\u003eAll times in UTC, please use a converter like \u003ca href=\"https://www.timeanddate.com/worldclock/converter.html?iso=20210713T140000\u0026#x26;p1=1440\"\u003ethis one\u003c/a\u003e to convert to your local time.\u003c/p\u003e\n\u003cp\u003eWe do not distinguish between workshop papers and Findings of the ACL papers that are being presented - they are all great! Links to all papers are coming soon!\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eTime (UTC)\u003c/th\u003e\n\u003cth\u003eSession\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e11:30 - 12:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eWelcome and Explanation of Logistics\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e12:00 - 13:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePoster Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eEvaluating the Efficacy of Summarization Evaluation across Languages  \u003cbr /\u003e \u003cem\u003eFajri Koto, Jey Han Lau, and Timothy Baldwin\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eAutomatic Text Simplification for Social Good: Progress and Challenges   \u003cbr /\u003e  \u003cem\u003eSanja Stajner\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eFlesch-Kincaid is Not a Text Simplification Evaluation Metric \u003cbr /\u003e  \u003cem\u003eTeerapaun Tanprasert and David Kauchak\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eHuman Perception in Natural Language Generation \u003cbr /\u003e       \u003cem\u003eLorenzo De Mattei, Huiyuan Lai, Felice Dell'Orletta, and Malvina Nissim\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eSemantic Similarity Based Evaluation for Abstractive News Summarization \u003cbr /\u003e \u003cem\u003eFigen Beken Fikri, Kemal Oflazer, and Berrin Yanikoglu\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eShades of BLEU, Flavours of Success: The Case of MultiWOZ \u003cbr /\u003e \u003cem\u003eTomáš Nekvinda and Ondřej Dušek\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e13:00 - 13:45\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePanel Discussion with Hady Elsahar, Seraphina Goldfarb-Tarrant, He He, and Ehud Reiter\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e13:45 - 14:00\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eBreak\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e14:00 - 15:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eTalk Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ePersonalized Response Generation with Tensor Factorization   \u003cbr /\u003e  \u003cem\u003eZhenghui Wang, Lingxiao Luo, and Diyi Yang\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eA Review of Human Evaluation for Style Transfer   \u003cbr /\u003e  \u003cem\u003eEleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, and Marine Carpuat\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eGOT: Testing for Originality in Natural Language Generation   \u003cbr /\u003e  \u003cem\u003eJennifer Brooks and Abdou Youssef\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eEvaluating Text Generation from Discourse Representation Structures   \u003cbr /\u003e  \u003cem\u003eChunliu Wang, Rik van Noord, Arianna Bisazza, and Johan Bos\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e15:00 - 16:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePoster Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eDetecting Hallucinated Content in Conditional Neural Sequence Generation   \u003cbr /\u003e  \u003cem\u003eChunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Paco Guzman, Luke Zettlemoyer, and Marjan Ghazvininejad\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eSynthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation   \u003cbr /\u003e  \u003cem\u003ePrakhar Gupta, Yulia Tsvetkov, and Jeffrey Bigham\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ePerceptual Models of Machine-Edited Text   \u003cbr /\u003e  \u003cem\u003eElizabeth Merkhofer, Monica-Ann Mendoza, Rebecca Marvin, and John Henderson\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eImproving Automated Evaluation of Open Domain Dialog via Diverse Reference Augmentation   \u003cbr /\u003e  \u003cem\u003eVarun Gangal, Harsh Jhamtani, Eduard Hovy, and Taylor Berg-Kirkpatrick\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eXL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages   \u003cbr /\u003e  \u003cem\u003eTahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang, M. Sohel Rahman, and Rifat Shahriyar\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eHuman Evaluation of Creative NLG Systems: An Interdisciplinary Survey on Recent Papers   \u003cbr /\u003e  \u003cem\u003eMika Hämäläinen and Khalid Alnajjar\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e16:00 - 17:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eKeynote by Asli Celikyilmaz\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e17:00 - 17:45\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePanel Discussion with Anya Belz, Asli Celikyilmaz, Mike Lewis, Lisa Li, and Wang Lu\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e17:45 - 18:00\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eBreak\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e18:00 - 19:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eGEM Overview Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eThe GEM Benchmark: Natural Language Generation, its Evaluation and Metrics   \u003cbr /\u003e  \u003cem\u003eEveryone listed on the \u003ca href=\"/team\"\u003eGEM team page\u003c/a\u003e\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eReusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards   \u003cbr /\u003e  \u003cem\u003eAngelina McMillan-Major, Salomey Osei, Juan Diego Rodriguez, Pawan Sasanka Ammanamanchi, Sebastian Gehrmann, and Yacine Jernite\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ePreliminary Results of the GEM Thared Task   \u003cbr /\u003e  \u003cem\u003eGEM Organizers\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eNL-Augmenter: A Collaborative Effort to Transform and Filter Text Datasets   \u003cbr /\u003e  \u003cem\u003eKaustubh Dhole, Sebastian Gehrmann, Jascha Sohl-Dickstein, Varun Prashant Gangal, Tongshuang Wu, Simon Mille, Zhenhao Li, Aadesh Gupta, Samson Tan, Saad Mahmood, Ashish Shrivastava, Ondrej Dusek, and Jinho D. Choi\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e19:00 - 20:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eGEM System Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eStructure-to-Text Generation with Self-Training, Acceptability Classifiers and Context-Conditioning for the GEM Shared Task   \u003cbr /\u003e  \u003cem\u003eShreyan Bakshi, Soumya Batra, Peyman Heidari, Ankit Arun, Shashank Jain, and Michael White\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eNUIG-DSI’s submission to The GEM Benchmark 2021   \u003cbr /\u003e  \u003cem\u003eNivranshu Pasricha, Mihael Arcan, and Paul Buitelaar\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eSystem Description for the CommonGen task with the POINTER model   \u003cbr /\u003e  \u003cem\u003eAnna Shvets\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eSimpleNER Sentence Simplification System for GEM 2021   \u003cbr /\u003e  \u003cem\u003eK V Aditya Srivatsa, Monil Gokani, and Manish Shrivastava\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e20:00 - 21:00\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePoster Session\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eGO FIGURE: A Meta Evaluation of Factuality in Summarization   \u003cbr /\u003e  \u003cem\u003eSaadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, and Jianfeng Gao\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eTellMeWhy: A Dataset for Answering Why-Questions in Narratives   \u003cbr /\u003e  \u003cem\u003eYash Kumar Lal, Nathanael Chambers, Raymond Mooney and Niranjan Balasubramanian\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eIs Human Scoring the Best Criteria for Summary Evaluation?   \u003cbr /\u003e  \u003cem\u003eOleg Vasilyev and John Bohannon\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eAre Larger Pretrained Language Models Uniformly Better? Comparing Performance at the Instance Level   \u003cbr /\u003e  \u003cem\u003eRuiqi Zhong, Dhruba Ghosh, Dan Klein, and Jacob Steinhardt\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eElaborative Simplification: Content Addition and Explanation Generation in Text Simplification   \u003cbr /\u003e  \u003cem\u003eNeha Srikanth and Junyi Jessy Li\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eDecoding Methods for Neural Narrative Generation   \u003cbr /\u003e  \u003cem\u003eAlexandra DeLucia, Aaron Mueller, Xiang Lisa Li, and João Sedoc\u003c/em\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"important-dates\"\u003eImportant Dates\u003c/h2\u003e\n\u003ch3 id=\"workshop\"\u003eWorkshop\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eFebruary 2\u003c/code\u003e First Call for Shared Task Submissions and Papers, Release of the Training Data\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eMay 3\u003c/code\u003e Workshop Paper Due Date (excl. shared tasks) \u003cstrong\u003eUPDATED\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eMay 28\u003c/code\u003e  Notification of Acceptance (excl. shared tasks)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eJune 7\u003c/code\u003e  Camera-ready papers due (excl. shared tasks)\u003c/p\u003e\n\u003ch3 id=\"shared-task-dates\"\u003eShared Task Dates\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eModeling\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eFebruary 2\u003c/code\u003e Release of the training Data\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eMarch 29\u003c/code\u003e Release of the test sets\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eMay 14\u003c/code\u003e Modeling submissions due\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eJune 11\u003c/code\u003e System Descriptions and Analyses due\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eJune 25\u003c/code\u003e Notification of Acceptance (shared task)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eJuly 9\u003c/code\u003e Camera-ready papers and task descriptions due\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eAugust 5-6\u003c/code\u003e Workshop Dates\u003c/p\u003e\n\u003ch2 id=\"organization\"\u003eOrganization\u003c/h2\u003e\n\u003cp\u003eThe workshop is organized by\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://atcbosselut.github.io/\"\u003eAntoine Bosselut\u003c/a\u003e (Stanford University)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.cs.cornell.edu/~esindurmus/\"\u003eEsin Durmus\u003c/a\u003e (Cornell University)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://vgtomahawk.github.io/\"\u003eVarun Prashant Gangal\u003c/a\u003e (Carnegie Mellon University)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://sebastiangehrmann.com\"\u003eSebastian Gehrmann\u003c/a\u003e (Google Research)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://yjernite.github.io/\"\u003eYacine Jernite\u003c/a\u003e (Hugging Face)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://homepages.inf.ed.ac.uk/lperez/\"\u003eLaura Perez-Beltrachini\u003c/a\u003e (University of Edinburgh)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://webpages.uncc.edu/sshaikh2/\"\u003eSamira Shaikh\u003c/a\u003e (UNC Charlotte)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cocoxu.github.io/\"\u003eWei Xu\u003c/a\u003e (Georgia Tech)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe shared task and the GEM environment is organized by a larger team which is listed on \u003ca href=\"/team\"\u003ethis page\u003c/a\u003e.\u003c/p\u003e\n","title":"GEM Workshop at ACL 2021"}},"__N_SSG":true},"page":"/workshop","query":{},"buildId":"ZF0k6kTxsf5RFK0SVnZki","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon","href":"/favicon.ico"}],["meta",{"name":"description","content":"Benchmark natural language generation systems with GEM."}],["meta",{"property":"og:image","content":"https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light\u0026md=1\u0026fontSize=100px\u0026images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"}],["meta",{"name":"og:title","content":"GEM"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["title",{"children":"GEM Workshop 2021"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-e3f5e01e6e72982ceda3.js"></script><script src="/_next/static/chunks/main-03338d1f0abd6c64b75e.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.4df82c4704a0136f6a4b.js" async=""></script><script src="/_next/static/chunks/commons.c6a8bf6988d7f4eaa7c5.js" async=""></script><script src="/_next/static/chunks/pages/_app-5b2207eda8db40c16cba.js" async=""></script><script src="/_next/static/chunks/cb1608f2.a574dc0b5846fc81ad3b.js" async=""></script><script src="/_next/static/chunks/1558ef9ce728a667623917e07efc98a0687ed212.cdf705ea9d3ade502405.js" async=""></script><script src="/_next/static/chunks/pages/workshop-edef57020c68610304bb.js" async=""></script><script src="/_next/static/ZF0k6kTxsf5RFK0SVnZki/_buildManifest.js" async=""></script><script src="/_next/static/ZF0k6kTxsf5RFK0SVnZki/_ssgManifest.js" async=""></script></body></html>