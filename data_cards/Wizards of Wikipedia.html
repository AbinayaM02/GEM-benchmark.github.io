<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Wizards of Wikipedia</title><link rel="preload" href="/_next/static/css/84e1b0eac45af8c581dd.css" as="style"/><link rel="stylesheet" href="/_next/static/css/84e1b0eac45af8c581dd.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a297635309d8dd71839d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a297635309d8dd71839d.css" data-n-p=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-78579f6fa91284b50170.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1d36bc031662b4dc4c28.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.c6a8bf6988d7f4eaa7c5.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-80091f437f1546754d80.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.a574dc0b5846fc81ad3b.js" as="script"/><link rel="preload" href="/_next/static/chunks/092e3b2ab0e90d672687ffd4e2946e7b752c34a5.7c2b6d748faa1d2422f2.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/data_cards/%5Bid%5D-6006300e13a531c344f9.js" as="script"/></head><body><div id="__next"><header class="layout_header__2rhWq"><div class="navbar_navwrapper__15zia"><div class="navbar_gradbar__1Xi5u"></div><nav class="navbar_navbar__3gnco"><span class="utils_headingLg__de7p0 navbar_navbarlogo__PLEwr"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__358pJ" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar__QVPSR" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__3ICSG navbar_pushright__3G2DM"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/get_started">How To</a></li><li class="navbar_navitem__3ICSG"><a href="/results">Results</a></li><li class="navbar_navitem__3ICSG"><a href="#">Paper</a></li><li class="navbar_navitem__3ICSG"><a href="/team">Team</a></li><li class="navbar_navitem__3ICSG"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__2t4v2"><main><article><span class="utils_headingXl__1XecN">Wizards of Wikipedia</span><span class="utils_smallSpace__375iy"></span><span class="utils_lightText__12Ckm">Dialog</span><div><h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#dataset-description">Dataset Description</a>
<ul>
<li><a href="#dataset-and-task-summary">Dataset and Task Summary</a></li>
<li><a href="#why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</a></li>
<li><a href="#languages">Languages</a></li>
</ul>
</li>
<li><a href="#meta-information">Meta Information</a>
<ul>
<li><a href="#dataset-curators">Dataset Curators</a></li>
<li><a href="#licensing-information">Licensing Information</a></li>
<li><a href="#citation-information">Citation Information</a></li>
<li><a href="#leaderboard">Leaderboard</a></li>
</ul>
</li>
<li><a href="#dataset-structure">Dataset Structure</a>
<ul>
<li><a href="#data-instances">Data Instances</a></li>
<li><a href="#data-fields">Data Fields</a></li>
<li><a href="#data-statistics">Data Statistics</a></li>
</ul>
</li>
<li><a href="#dataset-creation">Dataset Creation</a>
<ul>
<li><a href="#curation-rationale">Curation Rationale</a></li>
<li><a href="#communicative-goal">Communicative Goal</a></li>
<li><a href="#source-data">Source Data</a>
<ul>
<li><a href="#initial-data-collection-and-normalization">Initial Data Collection and Normalization</a></li>
</ul>
</li>
<li><a href="#annotations">Annotations</a>
<ul>
<li><a href="#annotation-process">Annotation process</a></li>
<li><a href="#who-are-the-annotators">Who are the annotators?</a></li>
</ul>
</li>
<li><a href="#personal-and-sensitive-information">Personal and Sensitive Information</a></li>
</ul>
</li>
<li><a href="#changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</a></li>
<li><a href="#considerations-for-using-the-data">Considerations for Using the Data</a>
<ul>
<li><a href="#social-impact-of-the-dataset">Social Impact of the Dataset</a></li>
<li><a href="#impact-on-underserved-communities">Impact on Underserved Communities</a></li>
<li><a href="#discussion-of-biases">Discussion of Biases</a></li>
<li><a href="#other-known-limitations">Other Known Limitations</a></li>
</ul>
</li>
<li><a href="#getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</a></li>
</ul>
<h2 id="dataset-description">Dataset Description</h2>
<ul>
<li><strong>Homepage:</strong> <a href="https://parl.ai/projects/wizard_of_wikipedia/">Wizard of Wikipedia Homepage</a></li>
<li><strong>Repository:</strong> <a href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/wizard_of_wikipedia">Wizard of Wikipedia task in PARLAI repo</a></li>
<li><strong>Paper:</strong> [Wizard of Wikipedia: Knowledge-Powered Conversational agents</li>
</ul>
<p>](<a href="https://arxiv.org/abs/1811.01241">https://arxiv.org/abs/1811.01241</a>)</p>
<ul>
<li><strong>Point of Contact:</strong> Option 1: Contacting via creating an issue on PARLAI <a href="https://github.com/facebookresearch/ParlAI">github repo</a>. Option 2:</li>
</ul>
<p><a href="%7Bedinan,roller,kshuster,angelafan,michaelauli,jase%7D@fb.com">Contact authors on the above paper</a></p>
<h3 id="dataset-and-task-summary">Dataset and Task Summary</h3>
<p>Task Summary:
The Wizard of Wikipedia is an open-domain dialogue task for training agents that can converse knowledgably about open-domain topics. In open-domain dialogue intelligent agents should exhibit the use of knowledge. This could simply be done by training models which "generate and hope" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output. Through grounded dialog datasets, one could rather train models that employing recalled knowledge as context. The goal here is to retrieving knowledge (relevant to context) from wikipedia, reading and conditioning on it, and finally generating natural responses.</p>
<p>Dataset:
The dataset consists of conversations grounded with knowledge retrieved from Wikipedia. It contains 201k utterances from 22k dialogues spanning over 1300 diverse topics, split into train, test, and valid sets. The associated Wikipedia knowledge base has 5.4M articles and 93M sentences.</p>
<h3 id="why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</h3>
<p>Wizard-of-Wikipedia is one of the three datasets representing Dialog Generation NLG in GEM.</p>
<h3 id="languages">Languages</h3>
<p>Contains English text only</p>
<h2 id="meta-information">Meta Information</h2>
<h3 id="dataset-curators">Dataset Curators</h3>
<p>The dataset was curated by a team of researchers from Facebook: Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, Jason Weston.</p>
<h3 id="licensing-information">Licensing Information</h3>
<p>The <a href="https://parl.ai/projects/wizard_of_wikipedia/">project page</a> does not mention a license for the dataset. ParlAI repository has <a href="https://github.com/facebookresearch/ParlAI/blob/master/LICENSE">MIT License</a></p>
<h3 id="citation-information">Citation Information</h3>
<pre><code>@inproceedings{dinan2019wizard,
  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
  title={{W}izard of {W}ikipedia: Knowledge-powered Conversational Agents},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019},
}
</code></pre>
<h3 id="leaderboard">Leaderboard</h3>
<p>Project page has a <a href="https://parl.ai/projects/wizard_of_wikipedia/">leaderboard</a>.</p>
<h2 id="dataset-structure">Dataset Structure</h2>
<h3 id="data-instances">Data Instances</h3>
<p>Data example (Source: Running <code>parlai display_data -t wizard_of_wikipedia -dt train</code> after installing ParlAI library)</p>
<pre><code>chosen_topic: Science fiction 
A: I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.
W: I'm a huge fan of science fiction myself! 
A: Awesome! I really love how sci-fi storytellers focus on political/social/philosophical issues that would still be around even in the future. Makes them relatable.
W: I agree. One of my favorite forms of science fiction is anything related to time travel! I find it fascinating.
A: It's not quite sci-fi, but my favorite version of time travel is in Harry Potter and the Prisoner of Azkaban. Breaks zero logical rules.
W: And that's difficult to do when dealing with time travel. I actually haven't seen the latest Harry Potter movies. Guess it's time to check them out!
A: If you really want a look at the potential negative consequences of scientific innovation, what you should check out is the TV show Fringe. Incredibly well written.
</code></pre>
<h3 id="data-fields">Data Fields</h3>
<p>Brief description of some of the fields:</p>
<ul>
<li><code>chosen_topic</code>: topic of dialog</li>
<li><code>checked_sentence</code>: selected knowledge</li>
<li><code>actor_id</code>: 'apprentice' or 'wizard'</li>
<li><code>text</code>: dialog utterance text</li>
</ul>
<p>Thr original repository has more <a href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/tasks/wizard_of_wikipedia/worlds.py">details</a></p>
<h3 id="data-statistics">Data Statistics</h3>
<p>Some statistics for train split:</p>
<ul>
<li>Number of Utterances : 166,787</li>
<li>Number of Dialogues: 18,430</li>
<li>Number of Topics: 1,247</li>
<li>Average Turns per Dialogue: 9.0</li>
</ul>
<h2 id="dataset-creation">Dataset Creation</h2>
<h3 id="curation-rationale">Curation Rationale</h3>
<p>As mentioned in the Wizard-of-Wikipedia paper, goal of collecting data of wizard-apprentice conversations between humans is to then be able to train models which can replace the human wizard and speak to a human apprentice, similar to the procedure in Wizard of Oz experiments.</p>
<h3 id="communicative-goal">Communicative Goal</h3>
<p>Apprentice talks to the wizard freely, playing the role of a curious learner, eager to chat.
Human Wizard is asked discuss a topic with an eager apprentice.</p>
<h3 id="source-data">Source Data</h3>
<p>A set of 1365 natural, open-domain dialogue topics, each linked to a Wikipedia article, was crowd-sourced. These dialogues are on diverse topics such as commuting, Gouda cheese, music festivals, podcasts, and bowling.</p>
<p>At each step of the dialogue the wizard has access to a set of passages of knowledge which may be relevant to the given dialogue context. The top 7 articles (first paragraph only) for the last two turns of dialogue (by wizard and apprentice) and the article (first 10 sentences only) for the original topic, and present these articles to the wizard as knowledge context, along with their titles.</p>
<h4 id="initial-data-collection-and-normalization">Initial Data Collection and Normalization</h4>
<p>The final dialogue dataset consists of 22,311 dialogues with
201,999 turns, which is divided into 166,787 for train, 17,715 for validation, and 17,497 for test. The test set is split into two subsets, Test Seen and Test Unseen. Test Seen contains 533 overlapping topics with the training set with new dialogues about those topics. Test Unseen consists of 58 topics never seen before in train or validation.</p>
<h3 id="annotations">Annotations</h3>
<h4 id="annotation-process">Annotation process</h4>
<p>Authors stated the following annotation procedure in their paper:</p>
<ol>
<li>Either the wizard or apprentice is picked to choose the topic and speak first. The other</li>
</ol>
<p>player receives the topic information, and the conversation begins.
2. When the apprentice sends the wizard a message, the wizard is shown relevant knowledge
(described below), and chooses a relevant sentence in order to construct a response, or else
chooses the no sentence used option.
3. The Wizard responds to the apprentice basing their response on their chosen sentence.
4. The conversation repeats until one of the conversation partners ends the chat (after a minimum of 4 or 5 turns each, randomly chosen beforehand).</p>
<h4 id="who-are-the-annotators">Who are the annotators?</h4>
<p>Crowdworkers were recruited for data collection. More details about crowdworkers are not provided in the paper.</p>
<h3 id="personal-and-sensitive-information">Personal and Sensitive Information</h3>
<p>[N/A]</p>
<h2 id="changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</h2>
<p>None at present</p>
<h2 id="considerations-for-using-the-data">Considerations for Using the Data</h2>
<h3 id="social-impact-of-the-dataset">Social Impact of the Dataset</h3>
<p>The dataset would probably have similar societal impacts as most other open domain dialog datasets. There are several resources available for social impact of open domain dialog agents (such as <a href="https://dl.acm.org/doi/10.1145/3170427.3185372">SIG: chatbots for social good. Følstad et al 2018</a>).</p>
<h3 id="impact-on-underserved-communities">Impact on Underserved Communities</h3>
<p>The dataset is in English language only.
The set of seed topics used, though diverse, might not be representative of all communities.</p>
<h3 id="discussion-of-biases">Discussion of Biases</h3>
<p>The topics are crowdsourced, and maybe limited to topics relevant to only some communities.
Moreover, dialogues are collected through crowdsourcing, and may exhibit biased opinions on various topics.</p>
<h3 id="other-known-limitations">Other Known Limitations</h3>
<h2 id="getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</h2>
<p>Some useful resources:</p>
<ul>
<li><a href="https://arxiv.org/abs/1811.01241">Link to paper</a></li>
<li><a href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/wizard_of_wikipedia">ParlAI code for Wizards of Wikipedia</a></li>
<li><a href="https://huggingface.co/datasets/woz_dialogue#social-impact-of-dataset">Huggingface datasets</a></li>
</ul>
</div></article></main><div class="layout_push__1J9g0"></div></div><footer class="layout_footer__127N0 utils_eggshell__Njxsh"><span class="layout_backToHome__1vZsp"><a href="/">← Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__k083p">google group</a> for support.</span></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"Wizards of Wikipedia","contentHtml":"\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-description\"\u003eDataset Description\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#languages\"\u003eLanguages\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#meta-information\"\u003eMeta Information\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-curators\"\u003eDataset Curators\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#licensing-information\"\u003eLicensing Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citation-information\"\u003eCitation Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#leaderboard\"\u003eLeaderboard\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-structure\"\u003eDataset Structure\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#data-instances\"\u003eData Instances\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-fields\"\u003eData Fields\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-statistics\"\u003eData Statistics\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-creation\"\u003eDataset Creation\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#curation-rationale\"\u003eCuration Rationale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#communicative-goal\"\u003eCommunicative Goal\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#source-data\"\u003eSource Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#annotations\"\u003eAnnotations\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#annotation-process\"\u003eAnnotation process\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#who-are-the-annotators\"\u003eWho are the annotators?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#discussion-of-biases\"\u003eDiscussion of Biases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-known-limitations\"\u003eOther Known Limitations\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dataset-description\"\u003eDataset Description\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHomepage:\u003c/strong\u003e \u003ca href=\"https://parl.ai/projects/wizard_of_wikipedia/\"\u003eWizard of Wikipedia Homepage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRepository:\u003c/strong\u003e \u003ca href=\"https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/wizard_of_wikipedia\"\u003eWizard of Wikipedia task in PARLAI repo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePaper:\u003c/strong\u003e [Wizard of Wikipedia: Knowledge-Powered Conversational agents\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e](\u003ca href=\"https://arxiv.org/abs/1811.01241\"\u003ehttps://arxiv.org/abs/1811.01241\u003c/a\u003e)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePoint of Contact:\u003c/strong\u003e Option 1: Contacting via creating an issue on PARLAI \u003ca href=\"https://github.com/facebookresearch/ParlAI\"\u003egithub repo\u003c/a\u003e. Option 2:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"%7Bedinan,roller,kshuster,angelafan,michaelauli,jase%7D@fb.com\"\u003eContact authors on the above paper\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/h3\u003e\n\u003cp\u003eTask Summary:\nThe Wizard of Wikipedia is an open-domain dialogue task for training agents that can converse knowledgably about open-domain topics. In open-domain dialogue intelligent agents should exhibit the use of knowledge. This could simply be done by training models which \"generate and hope\" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output. Through grounded dialog datasets, one could rather train models that employing recalled knowledge as context. The goal here is to retrieving knowledge (relevant to context) from wikipedia, reading and conditioning on it, and finally generating natural responses.\u003c/p\u003e\n\u003cp\u003eDataset:\nThe dataset consists of conversations grounded with knowledge retrieved from Wikipedia. It contains 201k utterances from 22k dialogues spanning over 1300 diverse topics, split into train, test, and valid sets. The associated Wikipedia knowledge base has 5.4M articles and 93M sentences.\u003c/p\u003e\n\u003ch3 id=\"why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/h3\u003e\n\u003cp\u003eWizard-of-Wikipedia is one of the three datasets representing Dialog Generation NLG in GEM.\u003c/p\u003e\n\u003ch3 id=\"languages\"\u003eLanguages\u003c/h3\u003e\n\u003cp\u003eContains English text only\u003c/p\u003e\n\u003ch2 id=\"meta-information\"\u003eMeta Information\u003c/h2\u003e\n\u003ch3 id=\"dataset-curators\"\u003eDataset Curators\u003c/h3\u003e\n\u003cp\u003eThe dataset was curated by a team of researchers from Facebook: Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, Jason Weston.\u003c/p\u003e\n\u003ch3 id=\"licensing-information\"\u003eLicensing Information\u003c/h3\u003e\n\u003cp\u003eThe \u003ca href=\"https://parl.ai/projects/wizard_of_wikipedia/\"\u003eproject page\u003c/a\u003e does not mention a license for the dataset. ParlAI repository has \u003ca href=\"https://github.com/facebookresearch/ParlAI/blob/master/LICENSE\"\u003eMIT License\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"citation-information\"\u003eCitation Information\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e@inproceedings{dinan2019wizard,\n  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},\n  title={{W}izard of {W}ikipedia: Knowledge-powered Conversational Agents},\n  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},\n  year={2019},\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"leaderboard\"\u003eLeaderboard\u003c/h3\u003e\n\u003cp\u003eProject page has a \u003ca href=\"https://parl.ai/projects/wizard_of_wikipedia/\"\u003eleaderboard\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"dataset-structure\"\u003eDataset Structure\u003c/h2\u003e\n\u003ch3 id=\"data-instances\"\u003eData Instances\u003c/h3\u003e\n\u003cp\u003eData example (Source: Running \u003ccode\u003eparlai display_data -t wizard_of_wikipedia -dt train\u003c/code\u003e after installing ParlAI library)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003echosen_topic: Science fiction \nA: I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.\nW: I'm a huge fan of science fiction myself! \nA: Awesome! I really love how sci-fi storytellers focus on political/social/philosophical issues that would still be around even in the future. Makes them relatable.\nW: I agree. One of my favorite forms of science fiction is anything related to time travel! I find it fascinating.\nA: It's not quite sci-fi, but my favorite version of time travel is in Harry Potter and the Prisoner of Azkaban. Breaks zero logical rules.\nW: And that's difficult to do when dealing with time travel. I actually haven't seen the latest Harry Potter movies. Guess it's time to check them out!\nA: If you really want a look at the potential negative consequences of scientific innovation, what you should check out is the TV show Fringe. Incredibly well written.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"data-fields\"\u003eData Fields\u003c/h3\u003e\n\u003cp\u003eBrief description of some of the fields:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003echosen_topic\u003c/code\u003e: topic of dialog\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003echecked_sentence\u003c/code\u003e: selected knowledge\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eactor_id\u003c/code\u003e: 'apprentice' or 'wizard'\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etext\u003c/code\u003e: dialog utterance text\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThr original repository has more \u003ca href=\"https://github.com/facebookresearch/ParlAI/blob/master/parlai/tasks/wizard_of_wikipedia/worlds.py\"\u003edetails\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"data-statistics\"\u003eData Statistics\u003c/h3\u003e\n\u003cp\u003eSome statistics for train split:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNumber of Utterances : 166,787\u003c/li\u003e\n\u003cli\u003eNumber of Dialogues: 18,430\u003c/li\u003e\n\u003cli\u003eNumber of Topics: 1,247\u003c/li\u003e\n\u003cli\u003eAverage Turns per Dialogue: 9.0\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dataset-creation\"\u003eDataset Creation\u003c/h2\u003e\n\u003ch3 id=\"curation-rationale\"\u003eCuration Rationale\u003c/h3\u003e\n\u003cp\u003eAs mentioned in the Wizard-of-Wikipedia paper, goal of collecting data of wizard-apprentice conversations between humans is to then be able to train models which can replace the human wizard and speak to a human apprentice, similar to the procedure in Wizard of Oz experiments.\u003c/p\u003e\n\u003ch3 id=\"communicative-goal\"\u003eCommunicative Goal\u003c/h3\u003e\n\u003cp\u003eApprentice talks to the wizard freely, playing the role of a curious learner, eager to chat.\nHuman Wizard is asked discuss a topic with an eager apprentice.\u003c/p\u003e\n\u003ch3 id=\"source-data\"\u003eSource Data\u003c/h3\u003e\n\u003cp\u003eA set of 1365 natural, open-domain dialogue topics, each linked to a Wikipedia article, was crowd-sourced. These dialogues are on diverse topics such as commuting, Gouda cheese, music festivals, podcasts, and bowling.\u003c/p\u003e\n\u003cp\u003eAt each step of the dialogue the wizard has access to a set of passages of knowledge which may be relevant to the given dialogue context. The top 7 articles (first paragraph only) for the last two turns of dialogue (by wizard and apprentice) and the article (first 10 sentences only) for the original topic, and present these articles to the wizard as knowledge context, along with their titles.\u003c/p\u003e\n\u003ch4 id=\"initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/h4\u003e\n\u003cp\u003eThe final dialogue dataset consists of 22,311 dialogues with\n201,999 turns, which is divided into 166,787 for train, 17,715 for validation, and 17,497 for test. The test set is split into two subsets, Test Seen and Test Unseen. Test Seen contains 533 overlapping topics with the training set with new dialogues about those topics. Test Unseen consists of 58 topics never seen before in train or validation.\u003c/p\u003e\n\u003ch3 id=\"annotations\"\u003eAnnotations\u003c/h3\u003e\n\u003ch4 id=\"annotation-process\"\u003eAnnotation process\u003c/h4\u003e\n\u003cp\u003eAuthors stated the following annotation procedure in their paper:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEither the wizard or apprentice is picked to choose the topic and speak first. The other\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eplayer receives the topic information, and the conversation begins.\n2. When the apprentice sends the wizard a message, the wizard is shown relevant knowledge\n(described below), and chooses a relevant sentence in order to construct a response, or else\nchooses the no sentence used option.\n3. The Wizard responds to the apprentice basing their response on their chosen sentence.\n4. The conversation repeats until one of the conversation partners ends the chat (after a minimum of 4 or 5 turns each, randomly chosen beforehand).\u003c/p\u003e\n\u003ch4 id=\"who-are-the-annotators\"\u003eWho are the annotators?\u003c/h4\u003e\n\u003cp\u003eCrowdworkers were recruited for data collection. More details about crowdworkers are not provided in the paper.\u003c/p\u003e\n\u003ch3 id=\"personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/h3\u003e\n\u003cp\u003e[N/A]\u003c/p\u003e\n\u003ch2 id=\"changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/h2\u003e\n\u003cp\u003eNone at present\u003c/p\u003e\n\u003ch2 id=\"considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/h2\u003e\n\u003ch3 id=\"social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/h3\u003e\n\u003cp\u003eThe dataset would probably have similar societal impacts as most other open domain dialog datasets. There are several resources available for social impact of open domain dialog agents (such as \u003ca href=\"https://dl.acm.org/doi/10.1145/3170427.3185372\"\u003eSIG: chatbots for social good. Følstad et al 2018\u003c/a\u003e).\u003c/p\u003e\n\u003ch3 id=\"impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/h3\u003e\n\u003cp\u003eThe dataset is in English language only.\nThe set of seed topics used, though diverse, might not be representative of all communities.\u003c/p\u003e\n\u003ch3 id=\"discussion-of-biases\"\u003eDiscussion of Biases\u003c/h3\u003e\n\u003cp\u003eThe topics are crowdsourced, and maybe limited to topics relevant to only some communities.\nMoreover, dialogues are collected through crowdsourcing, and may exhibit biased opinions on various topics.\u003c/p\u003e\n\u003ch3 id=\"other-known-limitations\"\u003eOther Known Limitations\u003c/h3\u003e\n\u003ch2 id=\"getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/h2\u003e\n\u003cp\u003eSome useful resources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/1811.01241\"\u003eLink to paper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/wizard_of_wikipedia\"\u003eParlAI code for Wizards of Wikipedia\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/datasets/woz_dialogue#social-impact-of-dataset\"\u003eHuggingface datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","title":"Wizards of Wikipedia","type":"Dialog","motivation":"Knowledge conditioned open domain dialog."}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"Wizards of Wikipedia"},"buildId":"NB8atiUW0WY-G8YKw8NdS","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon","href":"/favicon.ico"}],["meta",{"name":"description","content":"Benchmark natural language generation systems with GEM."}],["meta",{"property":"og:image","content":"https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light\u0026md=1\u0026fontSize=100px\u0026images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"}],["meta",{"name":"og:title","content":"GEM"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["title",{"children":"GEM Wizards of Wikipedia"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-ff58146f96da6d6b6775.js"></script><script src="/_next/static/chunks/main-78579f6fa91284b50170.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1d36bc031662b4dc4c28.js" async=""></script><script src="/_next/static/chunks/commons.c6a8bf6988d7f4eaa7c5.js" async=""></script><script src="/_next/static/chunks/pages/_app-80091f437f1546754d80.js" async=""></script><script src="/_next/static/chunks/cb1608f2.a574dc0b5846fc81ad3b.js" async=""></script><script src="/_next/static/chunks/092e3b2ab0e90d672687ffd4e2946e7b752c34a5.7c2b6d748faa1d2422f2.js" async=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-6006300e13a531c344f9.js" async=""></script><script src="/_next/static/NB8atiUW0WY-G8YKw8NdS/_buildManifest.js" async=""></script><script src="/_next/static/NB8atiUW0WY-G8YKw8NdS/_ssgManifest.js" async=""></script></body></html>